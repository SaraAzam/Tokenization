{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tokenzation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdiPglpURSOE",
        "outputId": "0af8f905-1f1f-4bef-a2d1-a1dcf94bd72e"
      },
      "source": [
        "# import TweetTokenizer() method from nltk \n",
        "from nltk.tokenize import TweetTokenizer \n",
        "# Create a reference variable for Class TweetTokenizer \n",
        "tk = TweetTokenizer() \n",
        "# Create a string input \n",
        "gfg = \"This is an educational institute\"\n",
        "  \n",
        "# Use tokenize method \n",
        "geek = tk.tokenize(gfg) #for unigram tokenization\n",
        "  \n",
        "print(geek) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'an', 'educational', 'institute']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1dr9-ZyThkG",
        "outputId": "9e21b82f-d978-4ee6-e00c-59acfffd06cd"
      },
      "source": [
        "import nltk #bigram by using punkt tokenizer\n",
        "nltk.download('punkt')\n",
        "word_data = \"This is an educational institute\"\n",
        "nltk_tokens = nltk.word_tokenize(word_data)  \t\n",
        "print(list(nltk.trigrams(nltk_tokens)))#for bigram tokenization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[('This', 'is', 'an'), ('is', 'an', 'educational'), ('an', 'educational', 'institute')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlMRCbE9VPhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c13f06-2441-4a84-ff19-bb6b35089209"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "nltk.download('punkt')\n",
        "text =\"This is an educational institute\"\n",
        "token=nltk.word_tokenize(text)\n",
        "bigrams=ngrams(token,3)#3 for trigram"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "botN5lLKpn4G",
        "outputId": "47469e76-06a4-4a3a-d0a7-27b93de0e179"
      },
      "source": [
        "from nltk import everygrams #for each gram of tokenization \n",
        "list(everygrams('This is an educational institute', 1, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('T',),\n",
              " ('h',),\n",
              " ('i',),\n",
              " ('s',),\n",
              " (' ',),\n",
              " ('i',),\n",
              " ('s',),\n",
              " (' ',),\n",
              " ('a',),\n",
              " ('n',),\n",
              " (' ',),\n",
              " ('e',),\n",
              " ('d',),\n",
              " ('u',),\n",
              " ('c',),\n",
              " ('a',),\n",
              " ('t',),\n",
              " ('i',),\n",
              " ('o',),\n",
              " ('n',),\n",
              " ('a',),\n",
              " ('l',),\n",
              " (' ',),\n",
              " ('i',),\n",
              " ('n',),\n",
              " ('s',),\n",
              " ('t',),\n",
              " ('i',),\n",
              " ('t',),\n",
              " ('u',),\n",
              " ('t',),\n",
              " ('e',),\n",
              " ('T', 'h'),\n",
              " ('h', 'i'),\n",
              " ('i', 's'),\n",
              " ('s', ' '),\n",
              " (' ', 'i'),\n",
              " ('i', 's'),\n",
              " ('s', ' '),\n",
              " (' ', 'a'),\n",
              " ('a', 'n'),\n",
              " ('n', ' '),\n",
              " (' ', 'e'),\n",
              " ('e', 'd'),\n",
              " ('d', 'u'),\n",
              " ('u', 'c'),\n",
              " ('c', 'a'),\n",
              " ('a', 't'),\n",
              " ('t', 'i'),\n",
              " ('i', 'o'),\n",
              " ('o', 'n'),\n",
              " ('n', 'a'),\n",
              " ('a', 'l'),\n",
              " ('l', ' '),\n",
              " (' ', 'i'),\n",
              " ('i', 'n'),\n",
              " ('n', 's'),\n",
              " ('s', 't'),\n",
              " ('t', 'i'),\n",
              " ('i', 't'),\n",
              " ('t', 'u'),\n",
              " ('u', 't'),\n",
              " ('t', 'e')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}